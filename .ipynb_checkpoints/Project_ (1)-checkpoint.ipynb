{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22d61be3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/jeremycui/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/jeremycui/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     /Users/jeremycui/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "import re\n",
    "import regex\n",
    "import string\n",
    "import scipy as scp\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "nltk.download('stopwords')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569a4e62",
   "metadata": {},
   "source": [
    "### Loading and Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d8d14e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = pd.read_csv('https://cdn-lfs.huggingface.co/datasets/juliensimon/autonlp-data-song-lyrics-demo/367571c0d07193ad0c8d577124d27076615bd98493fc1f5f785771496e673682')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "6006486d",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = pd.read_csv('https://cdn-lfs.huggingface.co/datasets/juliensimon/autonlp-data-song-lyrics-demo/709af4b6afd2d6bfd890e558c61aba15068e4758417abfb5d86bdbd0397431da')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "1016395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = stopwords.words('English')\n",
    "stop_words = []\n",
    "for word in stop_word:\n",
    "    wo = re.sub(\"'\", \"\", word)\n",
    "    stop_words.append(wo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2ac14f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lyrics = []\n",
    "\n",
    "for lyrics in lyrics_df['Lyric'].tolist():\n",
    "    \n",
    "    lyrics_n = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", lyrics)\n",
    "    lyrics_n2 = lyrics_n.translate(str.maketrans('', '', string.punctuation))\n",
    "    lyrics_n3 = re.sub(' +', ' ', lyrics_n2)\n",
    "    lyrics_n4 = re.sub(r'[0-9]+', '', lyrics_n3)\n",
    "    \n",
    "    new_list_song = []\n",
    "    for word in lyrics_n4.split():\n",
    "        if word.lower() not in stop_words:\n",
    "            new_list_song.append(word)\n",
    "            new_song = \" \".join(new_list_song)\n",
    "    \n",
    "    new_lyrics.append(new_song)\n",
    "    \n",
    "lyrics_df['Lyric'] = new_lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "adf03165",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_lyrics_ = []\n",
    "\n",
    "for lyrics in val_df['Lyric'].tolist():\n",
    "    \n",
    "    lyrics_n = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", lyrics)\n",
    "    lyrics_n2 = lyrics_n.translate(str.maketrans('', '', string.punctuation))\n",
    "    lyrics_n3 = re.sub(' +', ' ', lyrics_n2)\n",
    "    lyrics_n4 = re.sub(r'[0-9]+', '', lyrics_n3)\n",
    "    \n",
    "    new_list_song = []\n",
    "    for word in lyrics_n4.split():\n",
    "        if word.lower() not in stop_words:\n",
    "            new_list_song.append(word)\n",
    "            new_song = \" \".join(new_list_song)\n",
    "    \n",
    "    new_lyrics_.append(new_song)\n",
    "    \n",
    "val_df['Lyric'] = new_lyrics_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a90c3579",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_df = pd.DataFrame(columns= ['Lyric','Genre'])\n",
    "lemma_df['Genre'] = lyrics_df['Genre0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9d1f893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemma_df_ = pd.DataFrame(columns= ['Lyric','Genre'])\n",
    "lemma_df_['Genre'] = val_df['Genre0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a62a62a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Hip Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Heavy Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Lyric        Genre\n",
       "0      NaN         Rock\n",
       "1      NaN         Rock\n",
       "2      NaN      Hip Hop\n",
       "3      NaN         Rock\n",
       "4      NaN  Heavy Metal\n",
       "...    ...          ...\n",
       "5384   NaN         Rock\n",
       "5385   NaN          Pop\n",
       "5386   NaN  Heavy Metal\n",
       "5387   NaN         Rock\n",
       "5388   NaN          Pop\n",
       "\n",
       "[5389 rows x 2 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "294d16a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list_full = []\n",
    "for lyric in lyrics_df['Lyric'].to_list():\n",
    "    new_song_list = []\n",
    "    new_song = \"\"\n",
    "    for word in lyric.split():\n",
    "        lem = WordNetLemmatizer()\n",
    "        lemm = lem.lemmatize(word, pos='v')\n",
    "        new_song_list.append(lemm)\n",
    "        new_song = \" \".join(new_song_list)\n",
    "    song_list_full.append(new_song)\n",
    "lemma_df['Lyric'] = song_list_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "a1f615ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>get butter Aiyo one thing sure keep Keep nice ...</td>\n",
       "      <td>Hip Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aye Sean Paul long side mandem call Jay Sean F...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Beauty find refuge Lovers wrap inside others l...</td>\n",
       "      <td>Indie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>change tune many time since weve meet Ill alwa...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>get Js roll get drink pour buy bottle club Cam...</td>\n",
       "      <td>Hip Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48488</th>\n",
       "      <td>Unforgettable face cant think name edge tongue...</td>\n",
       "      <td>Heavy Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48489</th>\n",
       "      <td>Shawty swing way put ass face Round round head...</td>\n",
       "      <td>Hip Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48490</th>\n",
       "      <td>Born catch Care fear Gear heart Meanings Fearf...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48491</th>\n",
       "      <td>Ive get nothing say today use word yesterday I...</td>\n",
       "      <td>Heavy Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48492</th>\n",
       "      <td>Going far Getting nowhere Going far way Going ...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48493 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Lyric        Genre\n",
       "0      get butter Aiyo one thing sure keep Keep nice ...      Hip Hop\n",
       "1      Aye Sean Paul long side mandem call Jay Sean F...          Pop\n",
       "2      Beauty find refuge Lovers wrap inside others l...        Indie\n",
       "3      change tune many time since weve meet Ill alwa...         Rock\n",
       "4      get Js roll get drink pour buy bottle club Cam...      Hip Hop\n",
       "...                                                  ...          ...\n",
       "48488  Unforgettable face cant think name edge tongue...  Heavy Metal\n",
       "48489  Shawty swing way put ass face Round round head...      Hip Hop\n",
       "48490  Born catch Care fear Gear heart Meanings Fearf...         Rock\n",
       "48491  Ive get nothing say today use word yesterday I...  Heavy Metal\n",
       "48492  Going far Getting nowhere Going far way Going ...          Pop\n",
       "\n",
       "[48493 rows x 2 columns]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "a7dc2de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "song_list_full = []\n",
    "for lyric in val_df['Lyric'].to_list():\n",
    "    new_song_list = []\n",
    "    new_song = \"\"\n",
    "    for word in lyric.split():\n",
    "        lem = WordNetLemmatizer()\n",
    "        lemm = lem.lemmatize(word, pos='v')\n",
    "        new_song_list.append(lemm)\n",
    "        new_song = \" \".join(new_song_list)\n",
    "    song_list_full.append(new_song)\n",
    "lemma_df_['Lyric'] = song_list_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a2d3173f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nineteen come town call Summer Love burn baby ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coat hat go Ive really cant look little empty ...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Use Body keep mine Yeah Im Durango number Take...</td>\n",
       "      <td>Hip Hop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet Burger King fell love soda machine take c...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end everything degenerate culture elegy reaper...</td>\n",
       "      <td>Heavy Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>see look face get ringworm Im sorry tell get r...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>Id move Rockferry Tomorrow Id build house baby...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>hear thunder hear rain force blow windows barr...</td>\n",
       "      <td>Heavy Metal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>Moving move Im suppose hold back keep move Pus...</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>ask change color hair ask need thirty two pair...</td>\n",
       "      <td>Pop</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Lyric        Genre\n",
       "0     nineteen come town call Summer Love burn baby ...         Rock\n",
       "1     coat hat go Ive really cant look little empty ...         Rock\n",
       "2     Use Body keep mine Yeah Im Durango number Take...      Hip Hop\n",
       "3     meet Burger King fell love soda machine take c...         Rock\n",
       "4     end everything degenerate culture elegy reaper...  Heavy Metal\n",
       "...                                                 ...          ...\n",
       "5384  see look face get ringworm Im sorry tell get r...         Rock\n",
       "5385  Id move Rockferry Tomorrow Id build house baby...          Pop\n",
       "5386  hear thunder hear rain force blow windows barr...  Heavy Metal\n",
       "5387  Moving move Im suppose hold back keep move Pus...         Rock\n",
       "5388  ask change color hair ask need thirty two pair...          Pop\n",
       "\n",
       "[5389 rows x 2 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd7904b",
   "metadata": {},
   "source": [
    "### Obtaining Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d2ce3711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremycui/opt/anaconda3/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "number_songs = 1000\n",
    "vectors = vectorizer.fit_transform(lemma_df['Lyric'].iloc[:number_songs].to_list())\n",
    "feature_names = vectorizer.get_feature_names()\n",
    "dense = vectors.todense()\n",
    "dense_list = dense.tolist()\n",
    "df = pd.DataFrame(dense_list, columns=feature_names)\n",
    "\n",
    "enc_genres = []\n",
    "for g in list(lemma_df['Genre']):\n",
    "    enc_genres.append(genres.index(g))\n",
    "# Still need to encode genre, figure out how to run entire dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "29ae7f9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaaaaaaaaaaaaaaaaah</th>\n",
       "      <th>aaaaah</th>\n",
       "      <th>aaahh</th>\n",
       "      <th>aaaww</th>\n",
       "      <th>aah</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zro</th>\n",
       "      <th>zu</th>\n",
       "      <th>zumba</th>\n",
       "      <th>álbum</th>\n",
       "      <th>ço</th>\n",
       "      <th>œcanâ</th>\n",
       "      <th>œhe</th>\n",
       "      <th>œyour</th>\n",
       "      <th>全身</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 11007 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aa  aaaaaaaaaaaaaaaaaaah  aaaaah  aaahh  aaaww  aah  aaliyah  abandon  \\\n",
       "0    0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "1    0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "2    0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "3    0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "4    0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "..   ...                   ...     ...    ...    ...  ...      ...      ...   \n",
       "995  0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "996  0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "997  0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "998  0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "999  0.0                   0.0     0.0    0.0    0.0  0.0      0.0      0.0   \n",
       "\n",
       "     abandoned  abc  ...  zro   zu  zumba  álbum   ço  œcanâ  œhe  œyour   全身  \\\n",
       "0          0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "1          0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "2          0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "3          0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "4          0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "..         ...  ...  ...  ...  ...    ...    ...  ...    ...  ...    ...  ...   \n",
       "995        0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "996        0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "997        0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "998        0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "999        0.0  0.0  ...  0.0  0.0    0.0    0.0  0.0    0.0  0.0    0.0  0.0   \n",
       "\n",
       "     Genre  \n",
       "0        4  \n",
       "1        0  \n",
       "2        3  \n",
       "3        1  \n",
       "4        4  \n",
       "..     ...  \n",
       "995      1  \n",
       "996      5  \n",
       "997      1  \n",
       "998      3  \n",
       "999      3  \n",
       "\n",
       "[1000 rows x 11007 columns]"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Genre'] = enc_genres[:1000]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31c6d21",
   "metadata": {},
   "source": [
    "## Fitting the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b009aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as skm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c76c239",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df.iloc[:,:-1], df.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b38927d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(multi_class='multinomial', random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "a7480da8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(multi_class='multinomial', random_state=1)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "df1a813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(lemma_df_['Lyric'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "ff8beda4",
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_genres_ = []\n",
    "for g in list(lemma_df_['Genre']):\n",
    "    enc_genres_.append(genres.index(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cf15690d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Lyric</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nineteen come town call Summer Love burn baby ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>coat hat go Ive really cant look little empty ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Use Body keep mine Yeah Im Durango number Take...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>meet Burger King fell love soda machine take c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>end everything degenerate culture elegy reaper...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5384</th>\n",
       "      <td>see look face get ringworm Im sorry tell get r...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>Id move Rockferry Tomorrow Id build house baby...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5386</th>\n",
       "      <td>hear thunder hear rain force blow windows barr...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5387</th>\n",
       "      <td>Moving move Im suppose hold back keep move Pus...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5388</th>\n",
       "      <td>ask change color hair ask need thirty two pair...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5389 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Lyric  Genre\n",
       "0     nineteen come town call Summer Love burn baby ...      1\n",
       "1     coat hat go Ive really cant look little empty ...      1\n",
       "2     Use Body keep mine Yeah Im Durango number Take...      4\n",
       "3     meet Burger King fell love soda machine take c...      1\n",
       "4     end everything degenerate culture elegy reaper...      5\n",
       "...                                                 ...    ...\n",
       "5384  see look face get ringworm Im sorry tell get r...      1\n",
       "5385  Id move Rockferry Tomorrow Id build house baby...      0\n",
       "5386  hear thunder hear rain force blow windows barr...      5\n",
       "5387  Moving move Im suppose hold back keep move Pus...      1\n",
       "5388  ask change color hair ask need thirty two pair...      0\n",
       "\n",
       "[5389 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemma_df_['Genre'] = enc_genres_\n",
    "lemma_df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "54b2d117",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = list(lemma_df_['Genre'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "c529ab92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jeremycui/opt/anaconda3/lib/python3.8/site-packages/sklearn/base.py:450: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "935ad37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "5bf5bb15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5269994433104472"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skm.accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7eb751",
   "metadata": {},
   "source": [
    " ### Unused Code For Now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e1ab77",
   "metadata": {},
   "outputs": [],
   "source": [
    "song = lyrics_df['Lyric'].iloc[0]\n",
    "new_song_list = []\n",
    "for word in song.split():\n",
    "    porter = PorterStemmer()\n",
    "    port = porter.stem(word)\n",
    "    new_song_list.append(port)\n",
    "new_song = \" \".join(new_song_list)\n",
    "print(new_song)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7d0ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lyr = lyrics_df['Lyric'].tolist()\n",
    "tfidf_ = TfidfTransformer(use_idf=True)\n",
    "v = TfidfVectorizer()\n",
    "x = v.fit_transform(lyr)\n",
    "feat_list = v.get_feature_names()\n",
    "#wordcount = countVectorizer.fit_transform(dataset)\n",
    "#newTfIdf = tfIdfTransformer.fit_transform(wordCount)\n",
    "#df = pd.DataFrame(newTfIdf[0].T.todense(), index=countVectorizer.get_feature_names(), columns=[\"TF-IDF\"])\n",
    "#df = df.sort_values('TF-IDF', ascending=False)\n",
    "print(feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f072f4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_n = re.sub(\"([\\(\\[]).*?([\\)\\]])\", \"\", \"[Intro: Method Man w/ sample] + (Sunny valentine). We got butter (8X). (The gun'll go the gun'll go.... The gun'll go...). [Raekwon]. Aiyo one thing for sure keep you of all. Keep a nice crib fly away keep to the point. Keep niggaz outta ya face who snakes. Keep bitches in they place keep the mac in a special place. Keep moving for papes keep cool keep doing what you doing. Keep it fly keep me in the crates. Cuz I will erase shit on the real note you'se a waste. It's right here for you I will lace you. Rip you and brace you put a nice W up on ya face. Word to mother you could get chased. It's nothing to taste blood on a thug if he gotta go. All I know is we be giving grace. This is a place from where we make tapes. We make 'em everywhere still in all we be making base. Y'all be making paste these little niggaz they be making shapes. Our shit is art yours is traced. [Chorus: Sunny Valentine]. This is the way that we rolling in the streets. You know when we roll we be packing that heat. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go.... [Method Man]. This is Poverty Island man these animals don't run. Slums where the ambulance don't come. Who got the best base? Fiends waiting to smoke some. Approach something ask him where he getting that coke from. My dudes hug blocks like samurai shogun. Cuz no V and no ones equalling no fun. Who want a treat they know huh? Body to go numb. My woman need funds plus her hair and her toes done. It is what it is though you fuck with the kid flow. That make it hard to get dough the harder to get gold. Harder the piff blow harder when it snow. The pinky and the wrist glow this here what we live for. Get gwop then get low but first thought. We gotta get the work off the gift and the curse boss. Yeah see I'm the shit yo the dirt in the fit no. Hustling from the get-go the motto is get more. [Chorus]. [Masta Killa]. We was quiet flashy brothers strapped all along. With the dirty .38 long twelve hour shift gate. Took case state to state you think he won't hold his weight?. Put ya money on the plate and watch it get scrapped. We get ape up in that club off that juice and Henn. And it's a no win situation fucking with them. You mean like Ewing at the front at the rim finger roll a Dutch. Million dollar stages touched techs gauges bust. Trust no one the lone shogun rugged Timb boot stomper. Damaging lyrical mass destruction launcher. Nothing can calm the quakeage when I break kid. Peace to my brothers up north doing state bids. [Chorus]. [Chorus 2: Sunny Valentine]. Whoa... this is the way we be rolling in the club. You know when we roll we be packing .32 snubs. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go the gun'll go the gun'll go. The gun'll go the gun'll go the gun'll go the gun'll go. [Outro: sample to fade]. We got butter...\")\n",
    "lyrics_n3 = lyrics_n.translate(str.maketrans('', '', string.punctuation))\n",
    "lyrics_n4 = re.sub(' +', ' ', lyrics_n3)\n",
    "\n",
    "list_clipped = ['a', 'the', 'is', 'are']\n",
    "new_list_song = []\n",
    "for word in lyrics_n4.split():\n",
    "    if word.lower() not in list_clipped:\n",
    "        new_list_song.append(word)\n",
    "new_song = \" \".join(new_list_song)\n",
    "\n",
    "new_song\n",
    "#print(lyrics_n4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0a76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def non_word(sentence):\n",
    "    words = sentence.split()\n",
    "    \n",
    "    for word in words:\n",
    "        w_ord = list(word)\n",
    "        consec = 1\n",
    "        for ind in range(1, len(w_ord) - 1):\n",
    "            if w_ord[ind] == w_ord[ind - 1]:\n",
    "                consec += 1\n",
    "                if consec == 3:\n",
    "                    words.remove(word)\n",
    "                    break\n",
    "            else:\n",
    "                consec = 1\n",
    "                \n",
    "    #return ' '.join(words)\n",
    "    return words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
